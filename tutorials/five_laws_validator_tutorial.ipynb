{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Laws Cognitive Governance Validator Tutorial\n",
    "\n",
    "This tutorial demonstrates how to use the Five Laws Validator tool to evaluate AI-generated content against SIM-ONE's Five Laws of Cognitive Governance.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Five Laws Validator evaluates text against:\n",
    "1. **Architectural Intelligence** - Intelligence from coordination, not brute force\n",
    "2. **Cognitive Governance** - Governed processes over unconstrained generation\n",
    "3. **Truth Foundation** - Absolute truth principles over probabilistic drift\n",
    "4. **Energy Stewardship** - Computational efficiency and resource awareness\n",
    "5. **Deterministic Reliability** - Consistent, predictable outcomes\n",
    "\n",
    "## ENHANCED FEATURES\n",
    "\n",
    "The validator includes important enhancements:\n",
    "- **Protocol Context Synthesis**: Automatically detects protocols from text patterns\n",
    "- **Text-Only Validation**: Works with plain text without requiring full runtime context\n",
    "- **Law2 Governance Scoring**: Now properly scores cognitive governance from text analysis (previously returned 0%)\n",
    "\n",
    "The tool analyzes your text for indicators of:\n",
    "- REP (Reasoning & Explanation Protocol): reasoning structures like \"therefore\", \"because\", \"implies\"\n",
    "- VVP (Validation & Verification Protocol): structured validation with \"FACTS:\", \"RULES:\", \"EVIDENCE:\"\n",
    "- ESL (Emotional State Layer): emotional awareness indicators\n",
    "- Truth Foundation Protocol: citations and evidence\n",
    "- Quality Assurance: structured organization with lists and sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to the tool\n",
    "TOOL_PATH = Path(\"../code/tools/run_five_laws_validator.py\")\n",
    "\n",
    "def validate_text(text, strictness=\"moderate\", format=\"json\"):\n",
    "    \"\"\"Helper function to validate text using the Five Laws Validator\"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"python\", str(TOOL_PATH), \"--text\", text, \"--strictness\", strictness, \"--format\", format],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    return json.loads(result.stdout) if format == \"json\" else result.stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Validation\n",
    "\n",
    "Let's validate a simple AI response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example AI response to validate\n",
    "response = \"\"\"Climate change is supported by overwhelming scientific evidence from multiple \n",
    "independent sources including atmospheric measurements, ice core data, and global temperature \n",
    "records. The consensus among climate scientists exceeds 97%.\"\"\"\n",
    "\n",
    "# Validate the response\n",
    "result = validate_text(response)\n",
    "\n",
    "# Display results\n",
    "print(f\"Overall Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"Status: {result['pass_fail_status']}\")\n",
    "print(f\"\\nIndividual Law Scores:\")\n",
    "print(f\"  Law 1 (Architectural Intelligence): {result['scores']['law1_architectural_intelligence']:.1f}%\")\n",
    "print(f\"  Law 2 (Cognitive Governance): {result['scores']['law2_cognitive_governance']:.1f}%\")\n",
    "print(f\"  Law 3 (Truth Foundation): {result['scores']['law3_truth_foundation']:.1f}%\")\n",
    "print(f\"  Law 4 (Energy Stewardship): {result['scores']['law4_energy_stewardship']:.1f}%\")\n",
    "print(f\"  Law 5 (Deterministic Reliability): {result['scores']['law5_deterministic_reliability']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Validation with Different Strictness Levels\n",
    "\n",
    "The validator supports three strictness levels: lenient, moderate, and strict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"AI systems can be helpful tools for various tasks.\"\n",
    "\n",
    "for strictness in [\"lenient\", \"moderate\", \"strict\"]:\n",
    "    result = validate_text(response, strictness=strictness)\n",
    "    print(f\"\\n{strictness.upper()} Mode:\")\n",
    "    print(f\"  Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "    print(f\"  Status: {result['pass_fail_status']}\")\n",
    "    if result.get('violations'):\n",
    "        print(f\"  Violations: {len(result['violations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Iterative Refinement Based on Recommendations\n",
    "\n",
    "When validation fails, the tool provides recommendations for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial response that may need refinement\n",
    "response = \"I think the answer is probably around 42, but I'm not entirely sure.\"\n",
    "\n",
    "result = validate_text(response, strictness=\"strict\")\n",
    "\n",
    "print(f\"Initial Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"Status: {result['pass_fail_status']}\")\n",
    "\n",
    "if result.get('violations'):\n",
    "    print(f\"\\nViolations:\")\n",
    "    for violation in result['violations']:\n",
    "        print(f\"  - {violation}\")\n",
    "\n",
    "if result.get('recommendations'):\n",
    "    print(f\"\\nRecommendations:\")\n",
    "    for rec in result['recommendations']:\n",
    "        print(f\"  - {rec}\")\n",
    "\n",
    "if result.get('strengths'):\n",
    "    print(f\"\\nStrengths:\")\n",
    "    for strength in result['strengths']:\n",
    "        print(f\"  - {strength}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Batch Validation\n",
    "\n",
    "Validate multiple responses and compare their compliance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [\n",
    "    \"The Earth orbits the Sun due to gravitational forces, completing one orbit approximately every 365.25 days.\",\n",
    "    \"I believe the Earth probably goes around the Sun or something like that.\",\n",
    "    \"Based on astronomical observations and Newtonian mechanics, Earth's orbital period is 365.256 days.\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for i, response in enumerate(responses, 1):\n",
    "    result = validate_text(response)\n",
    "    results.append(result)\n",
    "    print(f\"\\nResponse {i}:\")\n",
    "    print(f\"  Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "    print(f\"  Status: {result['pass_fail_status']}\")\n",
    "    print(f\"  Truth Foundation Score: {result['scores']['law3_truth_foundation']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Using Summary Format\n",
    "\n",
    "The tool also supports a human-readable summary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"\"\"Machine learning models require careful validation to ensure they generalize \n",
    "well to unseen data. Cross-validation and holdout sets are standard practices.\"\"\"\n",
    "\n",
    "summary = validate_text(response, format=\"summary\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Law 2 (Cognitive Governance) Scoring - ENHANCED FEATURE\n",
    "\n",
    "**Important**: The validator now properly scores Law 2 by detecting protocol indicators in your text.\n",
    "\n",
    "Previously, Law 2 would return 0% because it expected runtime protocol context. Now it analyzes text patterns to detect:\n",
    "- **REP indicators**: \"therefore\", \"because\", \"implies\", \"conclusion\"\n",
    "- **VVP indicators**: \"FACTS:\", \"RULES:\", \"EVIDENCE:\", \"VALIDATION:\"\n",
    "- **ESL indicators**: emotional awareness language\n",
    "- **Citations**: research references, studies, evidence\n",
    "- **Structure**: organized lists, sections, formatting\n",
    "\n",
    "Let's compare different text patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic text WITHOUT protocol indicators (lower Law 2 score)\n",
    "text_basic = \"The answer is 42. This is the result.\"\n",
    "\n",
    "result1 = validate_text(text_basic)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Basic Text (No Protocol Indicators)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Text: {text_basic}\")\n",
    "print(f\"\\nLaw 2 (Cognitive Governance): {result1['scores']['law2_cognitive_governance']:.1f}%\")\n",
    "print(f\"Overall Compliance: {result1['scores']['overall_compliance']:.1f}%\\n\")\n",
    "\n",
    "# Example 2: Text WITH reasoning indicators (higher Law 2 score)\n",
    "text_reasoning = \"\"\"Because the premise states that all humans are mortal, \n",
    "and Socrates is human, therefore we can conclude that Socrates is mortal. \n",
    "This follows logically from the given facts.\"\"\"\n",
    "\n",
    "result2 = validate_text(text_reasoning)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 2: Text WITH Reasoning Indicators (REP)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Detected: 'because', 'therefore', 'conclude', 'logically'\")\n",
    "print(f\"\\nLaw 2 (Cognitive Governance): {result2['scores']['law2_cognitive_governance']:.1f}%\")\n",
    "print(f\"Overall Compliance: {result2['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"Improvement: +{result2['scores']['law2_cognitive_governance'] - result1['scores']['law2_cognitive_governance']:.1f}%\\n\")\n",
    "\n",
    "# Example 3: Text WITH multiple protocol indicators (highest Law 2 score)\n",
    "text_governed = \"\"\"FACTS:\n",
    "- All mammals are warm-blooded\n",
    "- Whales are mammals\n",
    "\n",
    "RULES:\n",
    "- If all mammals are warm-blooded, and whales are mammals, then whales are warm-blooded\n",
    "\n",
    "EVIDENCE:\n",
    "Scientific research (Smith et al., 2020) confirms that whales maintain constant body temperature.\n",
    "\n",
    "VALIDATION:\n",
    "Therefore, we can conclude with high confidence that whales are warm-blooded animals.\"\"\"\n",
    "\n",
    "result3 = validate_text(text_governed)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 3: Fully Governed Text (REP + VVP + Citations)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Detected: FACTS, RULES, EVIDENCE, VALIDATION sections\")\n",
    "print(f\"Detected: Citations (Smith et al., 2020)\")\n",
    "print(f\"Detected: Reasoning ('therefore', 'conclude')\")\n",
    "print(f\"\\nLaw 2 (Cognitive Governance): {result3['scores']['law2_cognitive_governance']:.1f}%\")\n",
    "print(f\"Overall Compliance: {result3['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"Improvement: +{result3['scores']['law2_cognitive_governance'] - result1['scores']['law2_cognitive_governance']:.1f}%\")\n",
    "print(f\"\\n\u2713 This demonstrates the Law 2 enhancement!\")\n",
    "print(f\"  The validator now detects and rewards governed cognitive processes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 20: Command-Line Usage\n",
    "\n",
    "The tool can also be used directly from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using command line with text argument\n",
    "!python ../code/tools/run_five_laws_validator.py --text \"The speed of light is approximately 299,792,458 meters per second.\" --format summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using stdin pipe\n",
    "!echo \"Water freezes at 0\u00b0C and boils at 100\u00b0C at standard atmospheric pressure.\" | python ../code/tools/run_five_laws_validator.py --format summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 20: Integration with AI Response Pipeline\n",
    "\n",
    "Here's how to integrate the validator into an AI response generation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_governed_response(prompt, max_iterations=3):\n",
    "    \"\"\"\n",
    "    Generate an AI response and validate it against Five Laws.\n",
    "    Refine until it passes or max iterations reached.\n",
    "    \"\"\"\n",
    "    # Simulated AI response generation (replace with actual AI model)\n",
    "    def generate_response(prompt):\n",
    "        return f\"Response to: {prompt}. This is a factual answer based on established scientific principles.\"\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        response = generate_response(prompt)\n",
    "        result = validate_text(response, strictness=\"moderate\")\n",
    "        \n",
    "        print(f\"\\nIteration {iteration + 1}:\")\n",
    "        print(f\"  Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "        print(f\"  Status: {result['pass_fail_status']}\")\n",
    "        \n",
    "        if result['pass_fail_status'] == \"PASS\":\n",
    "            print(f\"  \u2705 Response passed governance validation!\")\n",
    "            return response, result\n",
    "        else:\n",
    "            print(f\"  \u26a0\ufe0f Refinement needed\")\n",
    "            if result.get('recommendations'):\n",
    "                print(f\"  Recommendations: {result['recommendations'][0]}\")\n",
    "    \n",
    "    print(f\"\\n\u26a0\ufe0f Max iterations reached. Returning best attempt.\")\n",
    "    return response, result\n",
    "\n",
    "# Test the governed response pipeline\n",
    "prompt = \"Explain quantum entanglement\"\n",
    "final_response, validation = generate_governed_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Five Laws Validator is a powerful tool for ensuring AI-generated content meets cognitive governance standards. Key takeaways:\n",
    "\n",
    "- Use **moderate** strictness for general-purpose validation\n",
    "- Use **strict** mode for scientific, medical, or legal content\n",
    "- Use **lenient** mode for creative or exploratory content\n",
    "- Always review recommendations when validation fails\n",
    "- Integrate validation into your AI pipeline for consistent governance\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore other SIM-ONE tools: REP (Reasoning), ESL (Emotional State), VVP (Validation)\n",
    "- Learn about protocol composition for complex workflows\n",
    "- Read the full documentation at [PAPER2AGENT_INTEGRATION.md](../PAPER2AGENT_INTEGRATION.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}