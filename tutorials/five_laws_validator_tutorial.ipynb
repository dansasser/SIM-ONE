{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Laws Cognitive Governance Validator Tutorial\n",
    "\n",
    "This tutorial demonstrates SIM-ONE's Five Laws validation system for ensuring AI-generated content adheres to cognitive governance principles.\n",
    "\n",
    "## What You'll Learn\n",
    "- Validate AI responses against the Five Laws of Cognitive Governance\n",
    "- Batch validate multiple responses and compare compliance\n",
    "- Iteratively refine text based on validation recommendations\n",
    "\n",
    "## The Five Laws of Cognitive Governance\n",
    "\n",
    "1. **Architectural Intelligence** - Intelligence emerges from coordination, not brute computational force\n",
    "2. **Cognitive Governance** - Governed, structured processes over unconstrained generation\n",
    "3. **Truth Foundation** - Grounded in absolute truth principles, not probabilistic drift\n",
    "4. **Energy Stewardship** - Computational efficiency and resource-aware design\n",
    "5. **Deterministic Reliability** - Consistent, predictable outcomes across executions\n",
    "\n",
    "## Validation Strictness Levels\n",
    "- **Lenient**: 60% compliance threshold - Good for exploratory content\n",
    "- **Moderate**: 70% compliance threshold - Standard for most use cases\n",
    "- **Strict**: 85% compliance threshold - For production governance systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Standard library imports\nimport sys\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List, Literal\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Add SIM-ONE to Python path\nSIMONE_ROOT = Path(\"../code\").resolve()\nsys.path.insert(0, str(SIMONE_ROOT))\n\n# Import Five Laws validators directly\nfrom mcp_server.protocols.governance.five_laws_validator.law1_architectural_intelligence import ArchitecturalIntelligenceProtocol\nfrom mcp_server.protocols.governance.five_laws_validator.law2_cognitive_governance import CognitiveGovernanceProtocol\nfrom mcp_server.protocols.governance.five_laws_validator.law3_truth_foundation import TruthFoundationProtocol\nfrom mcp_server.protocols.governance.five_laws_validator.law4_energy_stewardship import EnergyStewardshipProtocol\nfrom mcp_server.protocols.governance.five_laws_validator.law5_deterministic_reliability import DeterministicReliabilityProtocol\n\n# Configure plotting\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"✓ Setup complete\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiveLawsValidator:\n",
    "    \"\"\"\n",
    "    Unified validator for all Five Laws of Cognitive Governance.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize all five law protocols.\"\"\"\n",
    "        self.law1 = ArchitecturalIntelligenceProtocol()\n",
    "        self.law2 = CognitiveGovernanceProtocol()\n",
    "        self.law3 = TruthFoundationProtocol()\n",
    "        self.law4 = EnergyStewardshipProtocol()\n",
    "        self.law5 = DeterministicReliabilityProtocol()\n",
    "\n",
    "        # Strictness thresholds\n",
    "        self.thresholds = {\n",
    "            \"lenient\": 60.0,\n",
    "            \"moderate\": 70.0,\n",
    "            \"strict\": 85.0\n",
    "        }\n",
    "\n",
    "    def validate(\n",
    "        self,\n",
    "        text: str,\n",
    "        strictness: Literal[\"lenient\", \"moderate\", \"strict\"] = \"moderate\",\n",
    "        context: Optional[Dict[str, Any]] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate text against all Five Laws.\n",
    "\n",
    "        Args:\n",
    "            text: Text to validate\n",
    "            strictness: Validation threshold level\n",
    "            context: Optional context for validation\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with scores, violations, recommendations, and pass/fail status\n",
    "        \"\"\"\n",
    "        if not text or not text.strip():\n",
    "            raise ValueError(\"Text to validate cannot be empty\")\n",
    "\n",
    "        # Prepare validation context\n",
    "        validation_context = context or {}\n",
    "        validation_context[\"text\"] = text\n",
    "\n",
    "        # Validate against each law\n",
    "        law1_result = self.law1.evaluate(validation_context)\n",
    "        law2_result = self.law2.evaluate(validation_context)\n",
    "        law3_result = self.law3.evaluate(validation_context)\n",
    "        law4_result = self.law4.evaluate(validation_context)\n",
    "        law5_result = self.law5.evaluate(validation_context)\n",
    "\n",
    "        # Extract scores\n",
    "        law1_score = law1_result.get(\"score\", 0.0)\n",
    "        law2_score = law2_result.get(\"score\", 0.0)\n",
    "        law3_score = law3_result.get(\"score\", 0.0)\n",
    "        law4_score = law4_result.get(\"score\", 0.0)\n",
    "        law5_score = law5_result.get(\"score\", 0.0)\n",
    "\n",
    "        # Calculate overall compliance\n",
    "        overall_compliance = (law1_score + law2_score + law3_score + law4_score + law5_score) / 5.0\n",
    "\n",
    "        # Collect violations and recommendations\n",
    "        violations = []\n",
    "        recommendations = []\n",
    "        strengths = []\n",
    "\n",
    "        for law_name, result in [\n",
    "            (\"Law 1 (Architectural Intelligence)\", law1_result),\n",
    "            (\"Law 2 (Cognitive Governance)\", law2_result),\n",
    "            (\"Law 3 (Truth Foundation)\", law3_result),\n",
    "            (\"Law 4 (Energy Stewardship)\", law4_result),\n",
    "            (\"Law 5 (Deterministic Reliability)\", law5_result)\n",
    "        ]:\n",
    "            violations.extend(result.get(\"violations\", []))\n",
    "            recommendations.extend(result.get(\"recommendations\", []))\n",
    "            if result.get(\"score\", 0) >= 80.0:\n",
    "                strengths.append(f\"{law_name}: Strong compliance\")\n",
    "\n",
    "        # Determine pass/fail status\n",
    "        threshold = self.thresholds[strictness]\n",
    "        if overall_compliance >= threshold:\n",
    "            status = \"PASS\"\n",
    "        elif overall_compliance >= threshold - 10:\n",
    "            status = \"CONDITIONAL\"\n",
    "        else:\n",
    "            status = \"FAIL\"\n",
    "\n",
    "        return {\n",
    "            \"scores\": {\n",
    "                \"law1_architectural_intelligence\": law1_score,\n",
    "                \"law2_cognitive_governance\": law2_score,\n",
    "                \"law3_truth_foundation\": law3_score,\n",
    "                \"law4_energy_stewardship\": law4_score,\n",
    "                \"law5_deterministic_reliability\": law5_score,\n",
    "                \"overall_compliance\": overall_compliance\n",
    "            },\n",
    "            \"pass_fail_status\": status,\n",
    "            \"strictness_level\": strictness,\n",
    "            \"threshold\": threshold,\n",
    "            \"violations\": violations,\n",
    "            \"recommendations\": recommendations,\n",
    "            \"strengths\": strengths\n",
    "        }\n",
    "\n",
    "\n",
    "# Initialize validator\n",
    "validator = FiveLawsValidator()\n",
    "print(\"✓ Five Laws Validator initialized\")\n",
    "print(f\"  Available strictness levels: {list(validator.thresholds.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Validate a Compliant Response\n",
    "\n",
    "Let's validate a response that demonstrates good governance principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "To analyze this dataset, I will use a coordinated multi-protocol approach:\n",
    "\n",
    "1. ESL protocol will assess emotional context\n",
    "2. REP protocol will handle logical reasoning\n",
    "3. Results will be validated against ground truth\n",
    "\n",
    "This architecture leverages protocol specialization for efficient processing\n",
    "while maintaining deterministic outcomes through structured workflows.\n",
    "\"\"\"\n",
    "\n",
    "result = validator.validate(text, strictness=\"moderate\")\n",
    "\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Overall Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"Status: {result['pass_fail_status']}\")\n",
    "print(f\"Strictness: {result['strictness_level']} (≥{result['threshold']}%)\")\n",
    "\n",
    "if result[\"strengths\"]:\n",
    "    print(f\"\\n✓ Strengths:\")\n",
    "    for strength in result[\"strengths\"]:\n",
    "        print(f\"  - {strength}\")\n",
    "\n",
    "if result[\"violations\"]:\n",
    "    print(f\"\\n✗ Violations ({len(result['violations'])})\")\n",
    "    for violation in result[\"violations\"][:3]:\n",
    "        print(f\"  - {violation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Validate a Non-Compliant Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Just use the biggest model available and throw more compute at it.\n",
    "The AI will figure it out eventually.\n",
    "\"\"\"\n",
    "\n",
    "result = validator.validate(text, strictness=\"moderate\")\n",
    "\n",
    "print(f\"Overall Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"Status: {result['pass_fail_status']}\\n\")\n",
    "\n",
    "print(\"Individual Law Scores:\")\n",
    "print(f\"  Law 1 (Architectural): {result['scores']['law1_architectural_intelligence']:.1f}%\")\n",
    "print(f\"  Law 2 (Governance): {result['scores']['law2_cognitive_governance']:.1f}%\")\n",
    "print(f\"  Law 3 (Truth): {result['scores']['law3_truth_foundation']:.1f}%\")\n",
    "print(f\"  Law 4 (Energy): {result['scores']['law4_energy_stewardship']:.1f}%\")\n",
    "print(f\"  Law 5 (Reliability): {result['scores']['law5_deterministic_reliability']:.1f}%\")\n",
    "\n",
    "print(f\"\\nTop Recommendations:\")\n",
    "for rec in result[\"recommendations\"][:5]:\n",
    "    print(f\"  • {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3-5: Various Strictness Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Lenient validation\n",
    "text = \"We'll use AI to help with this task.\"\n",
    "\n",
    "result_lenient = validator.validate(text, strictness=\"lenient\")\n",
    "print(f\"Lenient (≥60%): {result_lenient['pass_fail_status']} - {result_lenient['scores']['overall_compliance']:.1f}%\")\n",
    "\n",
    "# Example 4: Moderate validation (same text)\n",
    "result_moderate = validator.validate(text, strictness=\"moderate\")\n",
    "print(f\"Moderate (≥70%): {result_moderate['pass_fail_status']} - {result_moderate['scores']['overall_compliance']:.1f}%\")\n",
    "\n",
    "# Example 5: Strict validation (same text)\n",
    "result_strict = validator.validate(text, strictness=\"strict\")\n",
    "print(f\"Strict (≥85%): {result_strict['pass_fail_status']} - {result_strict['scores']['overall_compliance']:.1f}%\")\n",
    "\n",
    "print(f\"\\n💡 Same text, different thresholds produce different pass/fail outcomes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Output Format Options\n",
    "\n",
    "The validator supports both structured JSON and human-readable summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This approach uses protocol coordination for architectural intelligence.\"\n",
    "\n",
    "# JSON format (default - already shown in previous examples)\n",
    "result_json = validator.validate(text, strictness=\"moderate\")\n",
    "\n",
    "# Create human-readable summary\n",
    "def format_summary(result: Dict[str, Any]) -> str:\n",
    "    \"\"\"Format validation result as human-readable summary.\"\"\"\n",
    "    summary = []\n",
    "    summary.append(\"Five Laws Validation Report\")\n",
    "    summary.append(\"=\" * 80)\n",
    "    summary.append(f\"\\nOverall Compliance: {result['scores']['overall_compliance']:.1f}%\")\n",
    "    summary.append(f\"Status: {result['pass_fail_status']}\")\n",
    "    summary.append(f\"Strictness: {result['strictness_level']} (threshold: {result['threshold']}%)\\n\")\n",
    "\n",
    "    summary.append(\"Individual Law Scores:\")\n",
    "    summary.append(f\"  1. Architectural Intelligence:    {result['scores']['law1_architectural_intelligence']:.1f}%\")\n",
    "    summary.append(f\"  2. Cognitive Governance:          {result['scores']['law2_cognitive_governance']:.1f}%\")\n",
    "    summary.append(f\"  3. Truth Foundation:              {result['scores']['law3_truth_foundation']:.1f}%\")\n",
    "    summary.append(f\"  4. Energy Stewardship:            {result['scores']['law4_energy_stewardship']:.1f}%\")\n",
    "    summary.append(f\"  5. Deterministic Reliability:     {result['scores']['law5_deterministic_reliability']:.1f}%\\n\")\n",
    "\n",
    "    if result.get(\"violations\"):\n",
    "        summary.append(f\"Violations ({len(result['violations'])})\")\n",
    "        for v in result[\"violations\"][:5]:\n",
    "            summary.append(f\"  - {v}\")\n",
    "        summary.append(\"\")\n",
    "\n",
    "    if result.get(\"recommendations\"):\n",
    "        summary.append(f\"Recommendations ({len(result['recommendations'])})\")\n",
    "        for r in result[\"recommendations\"][:5]:\n",
    "            summary.append(f\"  - {r}\")\n",
    "\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "# Display summary format\n",
    "print(format_summary(result_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Batch Validation - Compare Multiple Responses\n",
    "\n",
    "Validate multiple AI responses and compare their compliance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple responses to validate\n",
    "responses = [\n",
    "    \"Use a coordinated multi-protocol architecture for efficient processing.\",\n",
    "    \"Just throw everything at a large language model.\",\n",
    "    \"Apply ESL for emotion analysis, then REP for reasoning with validation.\",\n",
    "    \"Try different approaches until something works.\",\n",
    "    \"Implement deterministic workflows with protocol specialization.\"\n",
    "]\n",
    "\n",
    "# Validate all responses\n",
    "results = []\n",
    "for i, text in enumerate(responses, 1):\n",
    "    result = validator.validate(text, strictness=\"moderate\")\n",
    "    results.append({\n",
    "        \"id\": i,\n",
    "        \"text_preview\": text[:50] + \"...\" if len(text) > 50 else text,\n",
    "        \"overall\": result[\"scores\"][\"overall_compliance\"],\n",
    "        \"law1\": result[\"scores\"][\"law1_architectural_intelligence\"],\n",
    "        \"law2\": result[\"scores\"][\"law2_cognitive_governance\"],\n",
    "        \"law3\": result[\"scores\"][\"law3_truth_foundation\"],\n",
    "        \"law4\": result[\"scores\"][\"law4_energy_stewardship\"],\n",
    "        \"law5\": result[\"scores\"][\"law5_deterministic_reliability\"],\n",
    "        \"status\": result[\"pass_fail_status\"],\n",
    "        \"violations\": len(result[\"violations\"]),\n",
    "        \"recommendations\": len(result[\"recommendations\"])\n",
    "    })\n",
    "\n",
    "# Create comparison table\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Batch Validation Comparison\")\n",
    "print(\"=\" * 120)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n📊 Summary:\")\n",
    "print(f\"  Total responses: {len(responses)}\")\n",
    "print(f\"  Passed: {(df['status'] == 'PASS').sum()}\")\n",
    "print(f\"  Conditional: {(df['status'] == 'CONDITIONAL').sum()}\")\n",
    "print(f\"  Failed: {(df['status'] == 'FAIL').sum()}\")\n",
    "print(f\"  Average compliance: {df['overall'].mean():.1f}%\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = df['id']\n",
    "width = 0.15\n",
    "x_pos = range(len(x))\n",
    "\n",
    "ax.bar([p - 2*width for p in x_pos], df['law1'], width, label='Law 1: Architectural', alpha=0.8)\n",
    "ax.bar([p - width for p in x_pos], df['law2'], width, label='Law 2: Governance', alpha=0.8)\n",
    "ax.bar(x_pos, df['law3'], width, label='Law 3: Truth', alpha=0.8)\n",
    "ax.bar([p + width for p in x_pos], df['law4'], width, label='Law 4: Energy', alpha=0.8)\n",
    "ax.bar([p + 2*width for p in x_pos], df['law5'], width, label='Law 5: Reliability', alpha=0.8)\n",
    "\n",
    "ax.axhline(y=70, color='red', linestyle='--', alpha=0.5, label='Moderate Threshold (70%)')\n",
    "ax.set_xlabel('Response ID', fontsize=12)\n",
    "ax.set_ylabel('Compliance Score (%)', fontsize=12)\n",
    "ax.set_title('Five Laws Compliance Comparison', fontsize=14)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(df['id'])\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"batch_validation_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Iterative Validation with Refinement\n",
    "\n",
    "Validate text iteratively, showing how to improve compliance over multiple rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def iterative_validate_with_refinement(\n    text: str,\n    max_iterations: int = 3,\n    threshold: float = 80.0,\n    strictness: Literal[\"lenient\", \"moderate\", \"strict\"] = \"moderate\"\n) -> Dict[str, Any]:\n    \"\"\"\n    Validate text with full state tracking for AI-client orchestration workflow.\n    \n    This function validates text and returns comprehensive feedback for iterative\n    refinement. Designed for AI clients (like Claude Code) to:\n    1. Call this function with text to validate\n    2. Receive validation scores and recommendations\n    3. Revise text based on recommendations\n    4. Call again with revised text until pass or max_iterations\n    \n    Args:\n        text: Text to validate (initial or revised)\n        max_iterations: Maximum validation attempts (default: 3)\n        threshold: Pass threshold percentage (default: 80.0)\n        strictness: Validation strictness level\n    \n    Returns:\n        Complete validation results with scores, recommendations, and pass/fail status\n    \"\"\"\n    # Validate the text\n    result = validator.validate(text, strictness=strictness)\n    \n    # Extract key metrics\n    overall_compliance = result[\"scores\"][\"overall_compliance\"]\n    status = result[\"pass_fail_status\"]\n    passed = overall_compliance >= threshold\n    \n    # Build comprehensive response\n    response = {\n        \"text\": text,\n        \"validation_result\": {\n            \"overall_compliance\": overall_compliance,\n            \"individual_scores\": {\n                \"law1_architectural_intelligence\": result[\"scores\"][\"law1_architectural_intelligence\"],\n                \"law2_cognitive_governance\": result[\"scores\"][\"law2_cognitive_governance\"],\n                \"law3_truth_foundation\": result[\"scores\"][\"law3_truth_foundation\"],\n                \"law4_energy_stewardship\": result[\"scores\"][\"law4_energy_stewardship\"],\n                \"law5_deterministic_reliability\": result[\"scores\"][\"law5_deterministic_reliability\"]\n            },\n            \"pass_fail_status\": status,\n            \"passed_threshold\": passed,\n            \"threshold\": threshold,\n            \"strictness\": strictness\n        },\n        \"violations\": result.get(\"violations\", []),\n        \"recommendations\": result.get(\"recommendations\", []),\n        \"strengths\": result.get(\"strengths\", []),\n        \"max_iterations\": max_iterations,\n        \"message\": f\"{'✓ Validation passed!' if passed else '✗ Validation failed.'} Score: {overall_compliance:.1f}% (threshold: {threshold}%)\"\n    }\n    \n    return response\n\n\n# Example 1: Validate passing text\nprint(\"Example 1: Text that passes validation\")\nprint(\"=\" * 80)\n\ngood_text = \"\"\"\nTo solve this problem, I'll use a coordinated multi-protocol architecture:\n1. ESL analyzes emotional context\n2. REP handles logical reasoning with deductive inference\n3. VVP validates rule structures before reasoning\n4. Results validated against ground truth\n\nThis approach ensures deterministic outcomes through structured workflows\nwhile maintaining computational efficiency through protocol specialization.\n\"\"\"\n\nresult1 = iterative_validate_with_refinement(good_text, threshold=70.0, strictness=\"moderate\")\nprint(f\"Score: {result1['validation_result']['overall_compliance']:.1f}%\")\nprint(f\"Passed: {result1['validation_result']['passed_threshold']}\")\nprint(f\"Message: {result1['message']}\")\n\n# Example 2: Validate failing text with recommendations\nprint(\"\\n\" + \"=\" * 80)\nprint(\"\\nExample 2: Text that needs refinement\")\nprint(\"-\" * 80)\n\npoor_text = \"Just use the biggest AI model and throw more compute at it.\"\n\nresult2 = iterative_validate_with_refinement(poor_text, threshold=70.0, strictness=\"moderate\")\nprint(f\"Score: {result2['validation_result']['overall_compliance']:.1f}%\")\nprint(f\"Passed: {result2['validation_result']['passed_threshold']}\")\nprint(f\"Message: {result2['message']}\")\nprint(f\"\\nTop 3 Recommendations:\")\nfor i, rec in enumerate(result2['recommendations'][:3], 1):\n    print(f\"  {i}. {rec}\")\n\n# Example 3: Simulated iterative workflow\nprint(\"\\n\" + \"=\" * 80)\nprint(\"\\nExample 3: Simulated Iterative Refinement Workflow\")\nprint(\"-\" * 80)\nprint(\"(Demonstrating how AI client refines text across iterations)\\n\")\n\n# Iteration 1\niter1_text = \"Use AI for analysis\"\nprint(f\"Iteration 1: \\\"{iter1_text}\\\"\")\niter1 = iterative_validate_with_refinement(iter1_text, threshold=75.0)\nprint(f\"  Score: {iter1['validation_result']['overall_compliance']:.1f}% | Passed: {iter1['validation_result']['passed_threshold']}\")\n\n# Iteration 2 (simulated AI revision)\niter2_text = \"Use coordinated protocol architecture with ESL for emotion analysis and REP for structured reasoning\"\nprint(f\"\\nIteration 2: \\\"{iter2_text}\\\"\")\niter2 = iterative_validate_with_refinement(iter2_text, threshold=75.0)\nprint(f\"  Score: {iter2['validation_result']['overall_compliance']:.1f}% | Passed: {iter2['validation_result']['passed_threshold']}\")\n\n# Iteration 3 (further refinement)\niter3_text = \"Implement coordinated multi-protocol architecture where ESL analyzes emotional context, REP performs deductive reasoning, and results are validated deterministically against ground truth for reliable outcomes\"\nprint(f\"\\nIteration 3: \\\"{iter3_text[:70]}...\\\"\")\niter3 = iterative_validate_with_refinement(iter3_text, threshold=75.0)\nprint(f\"  Score: {iter3['validation_result']['overall_compliance']:.1f}% | Passed: {iter3['validation_result']['passed_threshold']}\")\n\nprint(f\"\\n{'='*80}\")\nprint(\"Summary: Score improved from {:.1f}% → {:.1f}% → {:.1f}% across iterations\".format(\n    iter1['validation_result']['overall_compliance'],\n    iter2['validation_result']['overall_compliance'],\n    iter3['validation_result']['overall_compliance']\n))\nprint(\"Workflow shows how AI client uses validation feedback to refine responses\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 9: Context-Aware Validation\n",
    "\n",
    "Provide additional context to improve validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The system will learn from user interactions over time.\"\n",
    "\n",
    "# Without context\n",
    "result_basic = validator.validate(text, strictness=\"moderate\")\n",
    "\n",
    "# With context\n",
    "context = {\n",
    "    \"domain\": \"machine_learning\",\n",
    "    \"use_case\": \"adaptive_system\",\n",
    "    \"governance_required\": True\n",
    "}\n",
    "result_context = validator.validate(text, strictness=\"moderate\", context=context)\n",
    "\n",
    "print(\"Without Context:\")\n",
    "print(f\"  Overall Compliance: {result_basic['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"  Status: {result_basic['pass_fail_status']}\\n\")\n",
    "\n",
    "print(\"With Context:\")\n",
    "print(f\"  Overall Compliance: {result_context['scores']['overall_compliance']:.1f}%\")\n",
    "print(f\"  Status: {result_context['pass_fail_status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated SIM-ONE's Five Laws validation system:\n",
    "\n",
    "### Key Capabilities\n",
    "1. **Single text validation** - Validate individual AI responses against all Five Laws\n",
    "2. **Batch validation** - Compare multiple responses and identify best performers\n",
    "3. **Iterative refinement** - Track improvement across validation rounds\n",
    "4. **Flexible strictness** - Adjust thresholds based on use case requirements\n",
    "\n",
    "### When to Use Five Laws Validation\n",
    "- **AI Response Quality Control** - Ensure responses meet governance standards\n",
    "- **Model Comparison** - Evaluate different AI models against consistent criteria\n",
    "- **Content Moderation** - Validate AI-generated content before publication\n",
    "- **Compliance Auditing** - Document governance compliance for regulatory purposes\n",
    "\n",
    "### API Reference\n",
    "```python\n",
    "from mcp_server.protocols.governance.five_laws_validator.* import *\n",
    "\n",
    "validator = FiveLawsValidator()\n",
    "result = validator.validate(\n",
    "    text=\"Text to validate\",\n",
    "    strictness=\"moderate\",  # \"lenient\" | \"moderate\" | \"strict\"\n",
    "    context={\"domain\": \"...\"}  # optional\n",
    ")\n",
    "```\n",
    "\n",
    "### Output Structure\n",
    "```json\n",
    "{\n",
    "  \"scores\": {\n",
    "    \"law1_architectural_intelligence\": 85.2,\n",
    "    \"law2_cognitive_governance\": 78.5,\n",
    "    \"law3_truth_foundation\": 92.1,\n",
    "    \"law4_energy_stewardship\": 73.8,\n",
    "    \"law5_deterministic_reliability\": 88.3,\n",
    "    \"overall_compliance\": 83.6\n",
    "  },\n",
    "  \"pass_fail_status\": \"PASS\",\n",
    "  \"violations\": [...],\n",
    "  \"recommendations\": [...],\n",
    "  \"strengths\": [...]\n",
    "}\n",
    "```\n",
    "\n",
    "### Strictness Thresholds\n",
    "| Level | Threshold | Use Case |\n",
    "|-------|-----------|----------|\n",
    "| Lenient | ≥60% | Exploratory content, drafts |\n",
    "| Moderate | ≥70% | Standard production use |\n",
    "| Strict | ≥85% | Critical governance systems |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}