{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REP Reasoning & Explanation Protocol Tutorial\n",
    "\n",
    "This tutorial demonstrates SIM-ONE's REP protocol for performing advanced multi-modal reasoning across five reasoning types.\n",
    "\n",
    "## What You'll Learn\n",
    "- Execute deductive reasoning with formal logic rules\n",
    "- Perform inductive reasoning from observations to patterns\n",
    "- Apply abductive reasoning for best explanation hypothesis\n",
    "- Use analogical reasoning to transfer knowledge between domains\n",
    "- Conduct causal reasoning to understand cause-effect relationships\n",
    "\n",
    "## REP Reasoning Types\n",
    "\n",
    "1. **Deductive Reasoning** - From general rules to specific conclusions (logic-based)\n",
    "2. **Inductive Reasoning** - From specific observations to general patterns (pattern-based)\n",
    "3. **Abductive Reasoning** - From effects to best explanation hypotheses (inference-based)\n",
    "4. **Analogical Reasoning** - Transfer knowledge from source to target domain (similarity-based)\n",
    "5. **Causal Reasoning** - Analyze cause-and-effect relationships (temporal-based)\n",
    "\n",
    "## Key Concepts\n",
    "- **Reasoning Chain**: Step-by-step logical progression\n",
    "- **Confidence Scores**: Certainty level of conclusions (0.0 to 1.0)\n",
    "- **Evidence Tracking**: Source observations supporting conclusions\n",
    "- **Explanation Generation**: Human-readable reasoning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Standard library imports\nimport sys\nimport json\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List, Tuple\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom datetime import datetime\n\n# Add SIM-ONE to Python path\nSIMONE_ROOT = Path(\"../code\").resolve()\nsys.path.insert(0, str(SIMONE_ROOT))\n\n# Import REP protocol directly\nfrom mcp_server.protocols.rep.rep import AdvancedREP\n\n# Configure plotting\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (12, 8)\n\nprint(\"âœ“ Setup complete\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize REP protocol\n",
    "rep = AdvancedREP()\n",
    "\n",
    "print(\"âœ“ REP (Reasoning & Explanation Protocol) initialized\")\n",
    "print(f\"  Supported reasoning types: deductive, inductive, abductive, analogical, causal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Deductive Reasoning\n",
    "\n",
    "Deductive reasoning applies general rules to derive specific conclusions with logical certainty.\n",
    "\n",
    "**Format**: If premises are true, conclusion must be true.\n",
    "\n",
    "### Use Cases\n",
    "- Formal logic proofs\n",
    "- Rule-based expert systems\n",
    "- Contract compliance checking\n",
    "- Legal reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define facts and rules for deductive reasoning\n",
    "facts = [\n",
    "    \"All humans are mortal\",\n",
    "    \"Socrates is a human\"\n",
    "]\n",
    "\n",
    "rules = [\n",
    "    # Rule format: [[premises], conclusion]\n",
    "    [[\"All humans are mortal\", \"Socrates is a human\"], \"Socrates is mortal\"]\n",
    "]\n",
    "\n",
    "# Execute deductive reasoning\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"deductive\",\n",
    "    facts=facts,\n",
    "    rules=rules,\n",
    "    context=\"Classical logical syllogism\"\n",
    ")\n",
    "\n",
    "print(\"Deductive Reasoning Result:\")\n",
    "print(\"=\" * 80)\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "print(f\"\\nðŸ“Š Summary:\")\n",
    "print(f\"  Conclusions: {len(result.get('conclusions', []))}\")\n",
    "print(f\"  Average Confidence: {result.get('confidence', 0):.2f}\")\n",
    "\n",
    "if result.get(\"conclusions\"):\n",
    "    print(f\"\\nâœ“ Conclusion: {result['conclusions'][0]}\")\n",
    "\n",
    "if result.get(\"reasoning_chain\"):\n",
    "    print(f\"\\nðŸ”— Reasoning Chain:\")\n",
    "    for i, step in enumerate(result[\"reasoning_chain\"], 1):\n",
    "        print(f\"  {i}. {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Inductive Reasoning\n",
    "\n",
    "Inductive reasoning identifies patterns from specific observations to form general conclusions.\n",
    "\n",
    "**Format**: From multiple observations, infer probable patterns.\n",
    "\n",
    "### Use Cases\n",
    "- Scientific hypothesis formation\n",
    "- Market trend analysis\n",
    "- Customer behavior prediction\n",
    "- Pattern recognition in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations for pattern discovery\n",
    "observations = [\n",
    "    \"Sample 1 at 10Â°C: Reaction time is 120 seconds\",\n",
    "    \"Sample 2 at 20Â°C: Reaction time is 60 seconds\",\n",
    "    \"Sample 3 at 30Â°C: Reaction time is 30 seconds\",\n",
    "    \"Sample 4 at 40Â°C: Reaction time is 15 seconds\"\n",
    "]\n",
    "\n",
    "# Execute inductive reasoning\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"inductive\",\n",
    "    observations=observations,\n",
    "    context=\"Chemical reaction temperature analysis\"\n",
    ")\n",
    "\n",
    "print(\"Inductive Reasoning Result:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Pattern Identified: {result.get('pattern', 'None')}\")\n",
    "print(f\"Confidence: {result.get('confidence', 0):.2f}\")\n",
    "\n",
    "if result.get(\"general_rule\"):\n",
    "    print(f\"\\nâœ“ General Rule: {result['general_rule']}\")\n",
    "\n",
    "if result.get(\"evidence\"):\n",
    "    print(f\"\\nðŸ“ˆ Supporting Evidence:\")\n",
    "    for evidence in result[\"evidence\"]:\n",
    "        print(f\"  - {evidence}\")\n",
    "\n",
    "# Visualize the pattern\n",
    "temperatures = [10, 20, 30, 40]\n",
    "reaction_times = [120, 60, 30, 15]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(temperatures, reaction_times, 'bo-', linewidth=2, markersize=10)\n",
    "plt.xlabel(\"Temperature (Â°C)\", fontsize=12)\n",
    "plt.ylabel(\"Reaction Time (seconds)\", fontsize=12)\n",
    "plt.title(\"Inductive Pattern: Temperature vs Reaction Time\", fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"inductive_pattern.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Induced Pattern: As temperature doubles, reaction time halves (inverse relationship)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Abductive Reasoning\n",
    "\n",
    "Abductive reasoning infers the best explanation for observations by evaluating competing hypotheses.\n",
    "\n",
    "**Format**: Given effects, determine most likely cause.\n",
    "\n",
    "### Use Cases\n",
    "- Medical diagnosis\n",
    "- Root cause analysis\n",
    "- Fault detection in systems\n",
    "- Detective work and forensics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facts about the situation\n",
    "facts = [\n",
    "    \"The server response time increased from 50ms to 5000ms\",\n",
    "    \"CPU usage is at 95%\",\n",
    "    \"Memory usage is normal at 40%\",\n",
    "    \"Network traffic is normal\",\n",
    "    \"Disk I/O is normal\"\n",
    "]\n",
    "\n",
    "# Competing hypotheses to evaluate\n",
    "hypotheses = [\n",
    "    \"Database query is inefficient\",\n",
    "    \"Network congestion is occurring\",\n",
    "    \"Memory leak is present\",\n",
    "    \"CPU-intensive algorithm is running\",\n",
    "    \"Disk is failing\"\n",
    "]\n",
    "\n",
    "# Execute abductive reasoning\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"abductive\",\n",
    "    facts=facts,\n",
    "    hypotheses=hypotheses,\n",
    "    context=\"Server performance degradation diagnosis\"\n",
    ")\n",
    "\n",
    "print(\"Abductive Reasoning Result:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if result.get(\"best_explanation\"):\n",
    "    print(f\"âœ“ Best Explanation: {result['best_explanation']}\")\n",
    "    print(f\"  Confidence: {result.get('confidence', 0):.2f}\")\n",
    "\n",
    "if result.get(\"ranked_hypotheses\"):\n",
    "    print(f\"\\nðŸ“Š Ranked Hypotheses:\")\n",
    "    for i, hyp in enumerate(result[\"ranked_hypotheses\"], 1):\n",
    "        print(f\"  {i}. {hyp['hypothesis']} (score: {hyp['score']:.2f})\")\n",
    "\n",
    "if result.get(\"explanation\"):\n",
    "    print(f\"\\nðŸ’¡ Explanation:\")\n",
    "    print(f\"  {result['explanation']}\")\n",
    "\n",
    "# Visualize hypothesis rankings\n",
    "if result.get(\"ranked_hypotheses\"):\n",
    "    hyp_data = result[\"ranked_hypotheses\"]\n",
    "    labels = [h['hypothesis'][:30] + \"...\" if len(h['hypothesis']) > 30 else h['hypothesis']\n",
    "              for h in hyp_data]\n",
    "    scores = [h['score'] for h in hyp_data]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(labels, scores, color='steelblue', alpha=0.8)\n",
    "    plt.xlabel(\"Explanation Score\", fontsize=12)\n",
    "    plt.title(\"Abductive Reasoning: Hypothesis Rankings\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"abductive_hypotheses.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Analogical Reasoning\n",
    "\n",
    "Analogical reasoning transfers knowledge from a familiar domain (source) to an unfamiliar domain (target).\n",
    "\n",
    "**Format**: If A is similar to B, and A has property X, then B likely has property X.\n",
    "\n",
    "### Use Cases\n",
    "- Transfer learning in AI\n",
    "- Problem-solving by analogy\n",
    "- Educational explanations\n",
    "- Innovation and design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source domain (well-understood)\n",
    "source_case = {\n",
    "    \"domain\": \"Human circulatory system\",\n",
    "    \"components\": [\"heart\", \"arteries\", \"veins\", \"blood\"],\n",
    "    \"relationships\": [\n",
    "        \"heart pumps blood\",\n",
    "        \"arteries carry blood away from heart\",\n",
    "        \"veins carry blood back to heart\",\n",
    "        \"blood transports oxygen and nutrients\"\n",
    "    ],\n",
    "    \"properties\": [\n",
    "        \"closed loop system\",\n",
    "        \"pressure-driven flow\",\n",
    "        \"one-way valves prevent backflow\",\n",
    "        \"distributed network reaches all parts\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Target domain (less understood, seeking insights)\n",
    "target_case = {\n",
    "    \"domain\": \"City traffic system\",\n",
    "    \"components\": [\"traffic control center\", \"main roads\", \"side streets\", \"vehicles\"],\n",
    "    \"relationships\": [\n",
    "        \"control center manages traffic flow\",\n",
    "        \"main roads carry traffic outbound\",\n",
    "        \"side streets connect to main roads\",\n",
    "        \"vehicles transport people and goods\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Execute analogical reasoning\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"analogical\",\n",
    "    source_case=source_case,\n",
    "    target_case=target_case,\n",
    "    context=\"Understanding city traffic through biological analogy\"\n",
    ")\n",
    "\n",
    "print(\"Analogical Reasoning Result:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if result.get(\"analogies\"):\n",
    "    print(\"âœ“ Identified Analogies:\")\n",
    "    for analogy in result[\"analogies\"]:\n",
    "        print(f\"  {analogy['source']} â†” {analogy['target']}\")\n",
    "        if analogy.get(\"confidence\"):\n",
    "            print(f\"    Confidence: {analogy['confidence']:.2f}\")\n",
    "\n",
    "if result.get(\"transferred_properties\"):\n",
    "    print(f\"\\nðŸ“‹ Properties Transferred to Target Domain:\")\n",
    "    for prop in result[\"transferred_properties\"]:\n",
    "        print(f\"  â€¢ {prop}\")\n",
    "\n",
    "if result.get(\"insights\"):\n",
    "    print(f\"\\nðŸ’¡ Insights:\")\n",
    "    for insight in result[\"insights\"]:\n",
    "        print(f\"  - {insight}\")\n",
    "\n",
    "# Visualize analogy mapping\n",
    "if result.get(\"analogies\"):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes for source and target\n",
    "    for analogy in result[\"analogies\"]:\n",
    "        source = analogy[\"source\"]\n",
    "        target = analogy[\"target\"]\n",
    "        G.add_node(source, domain=\"source\")\n",
    "        G.add_node(target, domain=\"target\")\n",
    "        G.add_edge(source, target)\n",
    "\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Draw nodes by domain\n",
    "    source_nodes = [n for n, d in G.nodes(data=True) if d.get(\"domain\") == \"source\"]\n",
    "    target_nodes = [n for n, d in G.nodes(data=True) if d.get(\"domain\") == \"target\"]\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=source_nodes, node_color='lightblue',\n",
    "                           node_size=3000, label='Source Domain')\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=target_nodes, node_color='lightcoral',\n",
    "                           node_size=3000, label='Target Domain')\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.5, width=2)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=9, font_weight='bold')\n",
    "\n",
    "    plt.title(\"Analogical Mapping: Circulatory System â†” Traffic System\", fontsize=14)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"analogical_mapping.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Causal Reasoning\n",
    "\n",
    "Causal reasoning identifies cause-and-effect relationships from temporal event sequences.\n",
    "\n",
    "**Format**: If event A consistently precedes event B, A may cause B.\n",
    "\n",
    "### Use Cases\n",
    "- Root cause analysis\n",
    "- System failure prediction\n",
    "- Process optimization\n",
    "- Scientific causation studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal event sequence\n",
    "events = [\n",
    "    {\"timestamp\": \"2024-01-15T10:00:00\", \"event\": \"Database backup started\"},\n",
    "    {\"timestamp\": \"2024-01-15T10:05:00\", \"event\": \"Server CPU usage increased to 80%\"},\n",
    "    {\"timestamp\": \"2024-01-15T10:10:00\", \"event\": \"User complaints about slow response\"},\n",
    "    {\"timestamp\": \"2024-01-15T10:15:00\", \"event\": \"Database backup completed\"},\n",
    "    {\"timestamp\": \"2024-01-15T10:16:00\", \"event\": \"Server CPU usage returned to 20%\"},\n",
    "    {\"timestamp\": \"2024-01-15T10:17:00\", \"event\": \"User complaints ceased\"}\n",
    "]\n",
    "\n",
    "facts = [\n",
    "    \"Database backups are scheduled daily at 10:00\",\n",
    "    \"Backups are CPU-intensive operations\",\n",
    "    \"Server has limited CPU resources during business hours\"\n",
    "]\n",
    "\n",
    "# Execute causal reasoning\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"causal\",\n",
    "    events=events,\n",
    "    facts=facts,\n",
    "    context=\"Server performance issue analysis\"\n",
    ")\n",
    "\n",
    "print(\"Causal Reasoning Result:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if result.get(\"causal_chains\"):\n",
    "    print(\"âœ“ Identified Causal Chains:\")\n",
    "    for i, chain in enumerate(result[\"causal_chains\"], 1):\n",
    "        print(f\"\\n  Chain {i}:\")\n",
    "        print(f\"    Cause: {chain['cause']}\")\n",
    "        print(f\"    Effect: {chain['effect']}\")\n",
    "        print(f\"    Confidence: {chain.get('confidence', 0):.2f}\")\n",
    "        if chain.get(\"mechanism\"):\n",
    "            print(f\"    Mechanism: {chain['mechanism']}\")\n",
    "\n",
    "if result.get(\"recommendations\"):\n",
    "    print(f\"\\nðŸ’¡ Recommendations:\")\n",
    "    for rec in result[\"recommendations\"]:\n",
    "        print(f\"  â€¢ {rec}\")\n",
    "\n",
    "# Visualize causal timeline\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Parse timestamps and create timeline\n",
    "from datetime import datetime as dt\n",
    "times = [dt.fromisoformat(e[\"timestamp\"]) for e in events]\n",
    "start_time = times[0]\n",
    "relative_times = [(t - start_time).total_seconds() / 60 for t in times]  # minutes\n",
    "\n",
    "# Plot events\n",
    "y_positions = [1 if \"backup\" in e[\"event\"].lower() else\n",
    "               2 if \"CPU\" in e[\"event\"] else\n",
    "               3 for e in events]\n",
    "\n",
    "colors = ['blue' if \"backup\" in e[\"event\"].lower() else\n",
    "          'orange' if \"CPU\" in e[\"event\"] else\n",
    "          'red' for e in events]\n",
    "\n",
    "ax.scatter(relative_times, y_positions, s=200, c=colors, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "\n",
    "# Add event labels\n",
    "for i, (t, y, event) in enumerate(zip(relative_times, y_positions, events)):\n",
    "    label = event[\"event\"][:40] + \"...\" if len(event[\"event\"]) > 40 else event[\"event\"]\n",
    "    ax.annotate(label, (t, y), xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=9, bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Draw causal connections if available\n",
    "if result.get(\"causal_chains\"):\n",
    "    for chain in result[\"causal_chains\"]:\n",
    "        # Find event indices (simplified matching)\n",
    "        for i in range(len(events) - 1):\n",
    "            if chain[\"cause\"].lower() in events[i][\"event\"].lower():\n",
    "                for j in range(i + 1, len(events)):\n",
    "                    if chain[\"effect\"].lower() in events[j][\"event\"].lower():\n",
    "                        ax.annotate('', xy=(relative_times[j], y_positions[j]),\n",
    "                                   xytext=(relative_times[i], y_positions[i]),\n",
    "                                   arrowprops=dict(arrowstyle='->', lw=2, color='green', alpha=0.6))\n",
    "\n",
    "ax.set_xlabel(\"Time (minutes since start)\", fontsize=12)\n",
    "ax.set_ylabel(\"Event Category\", fontsize=12)\n",
    "ax.set_yticks([1, 2, 3])\n",
    "ax.set_yticklabels([\"Backup Events\", \"CPU Events\", \"User Experience\"], fontsize=10)\n",
    "ax.set_title(\"Causal Timeline Analysis\", fontsize=14)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"causal_timeline.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Example: Apply All Reasoning Types to One Scenario\n",
    "\n",
    "Let's solve a problem using all five reasoning types to see how they complement each other.\n",
    "\n",
    "**Scenario**: Investigating why a machine learning model's accuracy suddenly dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"ML model accuracy dropped from 95% to 70%\"\n",
    "\n",
    "print(f\"Scenario: {scenario}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Deductive reasoning - Apply known rules\n",
    "print(\"\\n1. DEDUCTIVE REASONING:\")\n",
    "deductive_result = rep.perform_reasoning(\n",
    "    reasoning_type=\"deductive\",\n",
    "    facts=[\n",
    "        \"Model accuracy dropped significantly\",\n",
    "        \"If training data distribution changes, model accuracy drops\"\n",
    "    ],\n",
    "    rules=[[\n",
    "        [\"Model accuracy dropped significantly\",\n",
    "         \"If training data distribution changes, model accuracy drops\"],\n",
    "        \"Training data distribution likely changed\"\n",
    "    ]],\n",
    "    context=\"Model performance degradation\"\n",
    ")\n",
    "print(f\"   Conclusion: {deductive_result.get('conclusions', ['None'])[0]}\")\n",
    "\n",
    "# 2. Inductive reasoning - Find patterns from logs\n",
    "print(\"\\n2. INDUCTIVE REASONING:\")\n",
    "inductive_result = rep.perform_reasoning(\n",
    "    reasoning_type=\"inductive\",\n",
    "    observations=[\n",
    "        \"Week 1: Accuracy 95%, Data source A only\",\n",
    "        \"Week 2: Accuracy 94%, Data source A only\",\n",
    "        \"Week 3: Accuracy 88%, Data sources A + B\",\n",
    "        \"Week 4: Accuracy 70%, Data sources A + B\"\n",
    "    ],\n",
    "    context=\"Historical accuracy analysis\"\n",
    ")\n",
    "print(f\"   Pattern: {inductive_result.get('pattern', 'None')}\")\n",
    "\n",
    "# 3. Abductive reasoning - Best explanation\n",
    "print(\"\\n3. ABDUCTIVE REASONING:\")\n",
    "abductive_result = rep.perform_reasoning(\n",
    "    reasoning_type=\"abductive\",\n",
    "    facts=[\n",
    "        \"Model accuracy is now 70%\",\n",
    "        \"New data source was added last week\",\n",
    "        \"Feature distributions differ between data sources\"\n",
    "    ],\n",
    "    hypotheses=[\n",
    "        \"Model overfitted to original data\",\n",
    "        \"New data source has different distribution\",\n",
    "        \"Model parameters need retuning\",\n",
    "        \"Hardware malfunction\",\n",
    "        \"Software bug introduced\"\n",
    "    ],\n",
    "    context=\"Model accuracy drop diagnosis\"\n",
    ")\n",
    "print(f\"   Best Explanation: {abductive_result.get('best_explanation', 'None')}\")\n",
    "\n",
    "# 4. Analogical reasoning - Learn from similar case\n",
    "print(\"\\n4. ANALOGICAL REASONING:\")\n",
    "analogical_result = rep.perform_reasoning(\n",
    "    reasoning_type=\"analogical\",\n",
    "    source_case={\n",
    "        \"domain\": \"Email spam detection\",\n",
    "        \"problem\": \"Accuracy dropped when users from new region added\",\n",
    "        \"solution\": \"Retrain with stratified sampling from all regions\"\n",
    "    },\n",
    "    target_case={\n",
    "        \"domain\": \"Current ML model\",\n",
    "        \"problem\": \"Accuracy dropped when new data source added\"\n",
    "    },\n",
    "    context=\"Learning from similar ML failures\"\n",
    ")\n",
    "print(f\"   Transferred Insight: {analogical_result.get('transferred_properties', ['None'])[0]}\")\n",
    "\n",
    "# 5. Causal reasoning - Identify cause-effect chain\n",
    "print(\"\\n5. CAUSAL REASONING:\")\n",
    "causal_result = rep.perform_reasoning(\n",
    "    reasoning_type=\"causal\",\n",
    "    events=[\n",
    "        {\"timestamp\": \"2024-01-01T00:00:00\", \"event\": \"Model deployed with 95% accuracy\"},\n",
    "        {\"timestamp\": \"2024-01-15T00:00:00\", \"event\": \"New data source B integrated\"},\n",
    "        {\"timestamp\": \"2024-01-16T00:00:00\", \"event\": \"First accuracy drop noticed (88%)\"},\n",
    "        {\"timestamp\": \"2024-01-22T00:00:00\", \"event\": \"Accuracy stabilized at 70%\"}\n",
    "    ],\n",
    "    facts=[\"Data source B has different feature distributions\"],\n",
    "    context=\"Timeline of model degradation\"\n",
    ")\n",
    "if causal_result.get(\"causal_chains\"):\n",
    "    chain = causal_result[\"causal_chains\"][0]\n",
    "    print(f\"   Causal Chain: {chain['cause']} â†’ {chain['effect']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTEGRATED CONCLUSION:\")\n",
    "print(\"The model's accuracy dropped because a new data source with different\")\n",
    "print(\"feature distributions was added. Solution: Retrain with stratified sampling\")\n",
    "print(\"from all data sources or normalize features across sources.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated SIM-ONE's REP protocol for multi-modal reasoning:\n",
    "\n",
    "### Reasoning Type Comparison\n",
    "\n",
    "| Type | Input | Output | Best For |\n",
    "|------|-------|--------|----------|\n",
    "| **Deductive** | Facts + Rules | Certain conclusions | Logical proofs, rule application |\n",
    "| **Inductive** | Observations | General patterns | Pattern discovery, hypothesis formation |\n",
    "| **Abductive** | Facts + Hypotheses | Best explanation | Diagnosis, root cause analysis |\n",
    "| **Analogical** | Source + Target cases | Transferred knowledge | Problem-solving, learning by analogy |\n",
    "| **Causal** | Events + Timeline | Cause-effect chains | Process analysis, prediction |\n",
    "\n",
    "### When to Use Each Type\n",
    "\n",
    "**Deductive**: When you have established rules and need to apply them logically\n",
    "\n",
    "**Inductive**: When you have data and need to find patterns or formulate hypotheses\n",
    "\n",
    "**Abductive**: When you need to explain observations with the most likely cause\n",
    "\n",
    "**Analogical**: When solving problems similar to ones you've solved before\n",
    "\n",
    "**Causal**: When analyzing temporal sequences to understand causation\n",
    "\n",
    "### API Reference\n",
    "```python\n",
    "from mcp_server.protocols.rep.rep import AdvancedREP\n",
    "\n",
    "rep = AdvancedREP()\n",
    "\n",
    "# Deductive\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"deductive\",\n",
    "    facts=[...],\n",
    "    rules=[[[premises], conclusion], ...]\n",
    ")\n",
    "\n",
    "# Inductive\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"inductive\",\n",
    "    observations=[...]\n",
    ")\n",
    "\n",
    "# Abductive\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"abductive\",\n",
    "    facts=[...],\n",
    "    hypotheses=[...]\n",
    ")\n",
    "\n",
    "# Analogical\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"analogical\",\n",
    "    source_case={...},\n",
    "    target_case={...}\n",
    ")\n",
    "\n",
    "# Causal\n",
    "result = rep.perform_reasoning(\n",
    "    reasoning_type=\"causal\",\n",
    "    events=[{\"timestamp\": ..., \"event\": ...}, ...],\n",
    "    facts=[...]\n",
    ")\n",
    "```\n",
    "\n",
    "### Output Structure\n",
    "All reasoning types return:\n",
    "```json\n",
    "{\n",
    "  \"reasoning_type\": \"...\",\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"conclusions\": [...],\n",
    "  \"reasoning_chain\": [...],\n",
    "  \"evidence\": [...],\n",
    "  \"explanation\": \"...\"\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}